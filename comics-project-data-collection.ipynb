{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c45e1f5-66ec-476c-9132-f8684a74479b",
   "metadata": {},
   "source": [
    "## Comics project - data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d85183-1d73-4852-b4a0-72b53f03343b",
   "metadata": {},
   "source": [
    "This project is non-profit, personal project for education purposes only.\n",
    "\n",
    "1) scrape comics db data - save them into a file\n",
    "(huge amount of data scraped from nonprofit db - save it to the csv and avoid another round of scraping)\n",
    "2) create sqlite3 db (separate comics.sql script) and import the gathered data\n",
    "\n",
    "Thanks to the people from https://www.comicsdb.cz/ project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f527c-2b82-4cf5-abc6-4406e906cb4c",
   "metadata": {},
   "source": [
    "### Importing all the neccessary libraries for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca838bad-239f-4eda-9c43-b4be9001c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "DRIVER_PATH = \"C:\\\\Users\\\\petr.musil\\\\Desktop\\\\python\\\\edgedriver\\\\msedgedriver.exe\"\n",
    "service = Service(executable_path = DRIVER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a81b5cf-2d0a-42ce-906d-f9bb30464b08",
   "metadata": {},
   "source": [
    "### Data collection - download all of the publishers links from the comicsdb.cz and export them to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3bf23f-5445-49bc-94b1-54a45ce6349c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    driver = webdriver.Edge(service=service)\n",
    "    publisher = \"https://www.comicsdb.cz/prehled-nakladatelstvi/1/\"\n",
    "    list_of_links = []\n",
    "    for num in list(range(1,8)):\n",
    "        driver.get(f'{publisher}{num}')    \n",
    "        time.sleep(1)\n",
    "        # wait for the element\n",
    "        element = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".card.text-center.p-2\")))\n",
    "        links = driver.find_element(by = By.CSS_SELECTOR, value = \".table-border-dashed\").find_elements(by = By.TAG_NAME, value = \"a\")\n",
    "        for link in links:\n",
    "            list_of_links.append([link.get_attribute(\"href\")])\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "filename = \"./data/links_publishers.csv\"\n",
    "with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(list_of_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53d8aba-2425-4e97-8e24-e55813a9d8a5",
   "metadata": {},
   "source": [
    "### Visit each webpage of a publisher from the source .csv file and get name, number of titles and link. Save the result to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2b356d2-830f-4f3e-a098-6c9d6f3cf540",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list_of_publisher_data = []\n",
    "    with open(\"./data/links_publishers.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            driver.get(row[0])\n",
    "            time.sleep(1)\n",
    "            publisher = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".font-weight-semibold\")))\n",
    "            number_of_titles = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".font-weight-bold.text-cdbred.ml-1\")))\n",
    "            list_of_publisher_data.append([publisher.text.strip(), number_of_titles.text.strip(), row[0].strip()])\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "filename = \"./data/output_publishers_data.csv\"\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=\";\")\n",
    "    csvwriter.writerow([\"name\", \"number_of_titles\", \"link\"])\n",
    "    csvwriter.writerows(list_of_publisher_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f731e-0c5a-4e8d-82e4-97d955658210",
   "metadata": {},
   "source": [
    "### Visit all titles overviews and save links to all the titles to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3a3667d-6249-4a5a-a72c-18006624f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    overview = \"https://www.comicsdb.cz/prehled-comicsu/6/\"\n",
    "    list_of_links = []\n",
    "    for num in list(range(1,106)):\n",
    "        driver.get(f'{overview}{num}')    \n",
    "        time.sleep(2)\n",
    "        # wait for the element\n",
    "        table_ = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".table.table-hover.table-xs\")))\n",
    "        links = driver.find_elements(by = By.CSS_SELECTOR, value = \".table-border-dashed a\")\n",
    "        #links = links.find_elements(by = By.TAG_NAME, value = \"a\")\n",
    "        for link in links:\n",
    "            list_of_links.append([link.get_attribute(\"href\")])\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "filename = \"./data/links_titles.csv\"\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(list_of_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151a273-6f60-4abc-a133-4ad029491156",
   "metadata": {},
   "source": [
    "### Visit all the titles details and get all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9e2af4-5767-4e2c-ac8e-df8cad9ab14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list_of_titles_data = []\n",
    "    with open(\"./data/links_titles.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            driver.get(row[0])\n",
    "            time.sleep(2)\n",
    "            title = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".font-weight-semibold\")))\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            title = soup.find(\"span\", \"font-weight-semibold\").text\n",
    "            basic_info = soup.find(\"small\")\n",
    "            try:\n",
    "                link_publisher = basic_info.find(\"a\").get(\"href\")\n",
    "            except:\n",
    "                link_publisher = \"NA\"\n",
    "            try:\n",
    "                year_pattern = re.compile(r'\\d{4}')\n",
    "                year = year_pattern.search(basic_info.text)\n",
    "                year = year.group()\n",
    "            except:            \n",
    "                year = \"NA\"\n",
    "            pages = \"NA\"\n",
    "            price = \"NA\"\n",
    "            dt_tags = soup.find_all(\"dt\")\n",
    "            for tag in dt_tags:\n",
    "                if \"Stran\" in tag.text:\n",
    "                    pages = tag.next_sibling.text\n",
    "                elif \"Cena\" in tag.text:\n",
    "                    price = tag.next_sibling.text\n",
    "            list_of_titles_data.append([title.strip(), year.strip(), row[0].strip(), link_publisher.strip(), pages.strip(), price.strip()])\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "filename = \"./data/output_titles_data.csv\"\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=\";\")\n",
    "    csvwriter.writerow([\"title\", \"year\", \"link_title\",\"link_publisher\", \"pages\", \"price\"])\n",
    "    csvwriter.writerows(list_of_titles_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e411459c-4c3e-4719-8664-5d1365d13d9c",
   "metadata": {},
   "source": [
    "### Clean the data from csv files, restructure them and import to sqlite3 db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c9daa2b-d57c-468f-8bf8-a53667bffa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10453 entries, 0 to 10452\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           10453 non-null  object \n",
      " 1   year            10453 non-null  int32  \n",
      " 2   link_title      10453 non-null  object \n",
      " 3   link_publisher  10391 non-null  object \n",
      " 4   pages           10453 non-null  int32  \n",
      " 5   price           9807 non-null   float64\n",
      " 6   publisher_id    10453 non-null  int32  \n",
      "dtypes: float64(1), int32(3), object(3)\n",
      "memory usage: 530.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "titles = pd.read_csv(\"./data/output_titles.csv\", delimiter=\";\")\n",
    "publishers = pd.read_csv(\"./data/output_publishers_data.csv\", delimiter=\";\")\n",
    "\n",
    "titles_origin = titles.copy()\n",
    "titles = titles[titles[\"link_publisher\"] == \"/nakladatelstvi/1/crew\"]\n",
    "titles[\"year\"] = titles[\"year\"].astype(int)\n",
    "mean_pages = titles[\"pages\"].mean()\n",
    "titles[\"pages\"] = titles[\"pages\"].fillna(mean_pages).astype(int)\n",
    "titles[\"price\"] = titles[\"price\"].str.replace(\" Kč\", \"\").astype(int)\n",
    "# if there is no year fill special value 0\n",
    "titles_origin[\"year\"] = titles_origin[\"year\"].fillna(0)\n",
    "titles_origin[\"year\"] = titles_origin[\"year\"].astype(int)\n",
    "mean_pages = titles_origin[\"pages\"].mean()\n",
    "titles_origin[\"pages\"] = titles_origin[\"pages\"].fillna(mean_pages).astype(int)\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].fillna(0)\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" Kč\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" h\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" K\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" k\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" Lei\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.strip().astype(float)\n",
    "\n",
    "# Save some space - get the same part of url as in the titles csv file.\n",
    "publishers[\"link\"] = publishers[\"link\"].apply(lambda x: urlparse(x).path)\n",
    "publishers.rename(columns = {\"index\": \"publisher_id\"}, inplace = True)\n",
    "\n",
    "# import publishers to the db - let them get their pubsliher_id in the db and export, then joinig with titles from csv and fetch the pubslisher_id to the titles\n",
    "try:\n",
    "    conn = sqlite3.connect(\"./db/comics.db\")\n",
    "    cur = conn.cursor()\n",
    "    # import publishers df to the sqlite3 db, change the name of index to publisher_id\n",
    "    publishers.to_sql('publishers', conn, if_exists='replace', index=True, index_label='publisher_id')\n",
    "    result = cur.execute(\"SELECT * FROM publishers;\")\n",
    "    rows = result.fetchall()\n",
    "    columns = [column[0] for column in cur.description]\n",
    "    publishers_final = pd.DataFrame(rows, columns=columns)\n",
    "    titles_origin_final = titles_origin.merge(publishers_final, how=\"left\", left_on=\"link_publisher\", right_on=\"link\")\n",
    "    titles_origin_final.drop([\"name\", \"number_of_titles\", \"link\"],  axis = 1, inplace=True)\n",
    "    # renaming column\n",
    "    titles_origin_final.rename(columns = {\"index\": \"publisher_id\"}, inplace = True)\n",
    "    # if there is no publisher assign some special id\n",
    "    titles_origin_final[\"publisher_id\"] = titles_origin_final[\"publisher_id\"].fillna(999999)\n",
    "    titles_origin_final[\"publisher_id\"] = titles_origin_final[\"publisher_id\"].astype(int)\n",
    "    titles_origin_final.to_sql('titles', conn, if_exists='replace', index=True, index_label='title_id')\n",
    "finally:\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
