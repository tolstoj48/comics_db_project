{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c45e1f5-66ec-476c-9132-f8684a74479b",
   "metadata": {},
   "source": [
    "## DB PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d85183-1d73-4852-b4a0-72b53f03343b",
   "metadata": {},
   "source": [
    "This project is non-profit, personal project for education purposes only.\n",
    "\n",
    "1) scrape comics db data - save them into file (huge amount of data scraped from nonprofit db - save it to the csv and avoid another round of scraping)\n",
    "2) create sqlite3 db (separate comics.sql script)\n",
    "3) import data from scraped .csv files\n",
    "4) connect a python command line tool to the db and allow users to search the db\n",
    "\n",
    "Thanks to the people from https://www.comicsdb.cz/ project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f527c-2b82-4cf5-abc6-4406e906cb4c",
   "metadata": {},
   "source": [
    "### Importing all the neccessary libraries for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca838bad-239f-4eda-9c43-b4be9001c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "DRIVER_PATH = \"C:\\\\Users\\\\petr.musil\\\\Desktop\\\\python\\\\edgedriver\\\\msedgedriver.exe\"\n",
    "service = Service(executable_path = DRIVER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a81b5cf-2d0a-42ce-906d-f9bb30464b08",
   "metadata": {},
   "source": [
    "### Data collection - download all of the publishers links from the comicsdb.cz and export them to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3bf23f-5445-49bc-94b1-54a45ce6349c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    driver = webdriver.Edge(service=service)\n",
    "    publisher = \"https://www.comicsdb.cz/prehled-nakladatelstvi/1/\"\n",
    "    list_of_links = []\n",
    "    for num in list(range(1,8)):\n",
    "        driver.get(f'{publisher}{num}')    \n",
    "        time.sleep(1)\n",
    "        # wait for the element\n",
    "        element = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".card.text-center.p-2\")))\n",
    "        links = driver.find_element(by = By.CSS_SELECTOR, value = \".table-border-dashed\").find_elements(by = By.TAG_NAME, value = \"a\")\n",
    "        for link in links:\n",
    "            list_of_links.append([link.get_attribute(\"href\")])\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "filename = \"./data/links_publishers.csv\"\n",
    "with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(list_of_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53d8aba-2425-4e97-8e24-e55813a9d8a5",
   "metadata": {},
   "source": [
    "### Visit each webpage of a publisher from the source .csv file and get name, number of titles and link. Save the result to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2b356d2-830f-4f3e-a098-6c9d6f3cf540",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list_of_publisher_data = []\n",
    "    with open(\"./data/links_publishers.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            driver.get(row[0])\n",
    "            time.sleep(1)\n",
    "            publisher = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".font-weight-semibold\")))\n",
    "            number_of_titles = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".font-weight-bold.text-cdbred.ml-1\")))\n",
    "            list_of_publisher_data.append([publisher.text.strip(), number_of_titles.text.strip(), row[0].strip()])\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "filename = \"./data/output_publishers_data.csv\"\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=\";\")\n",
    "    csvwriter.writerow([\"name\", \"number_of_titles\", \"link\"])\n",
    "    csvwriter.writerows(list_of_publisher_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f731e-0c5a-4e8d-82e4-97d955658210",
   "metadata": {},
   "source": [
    "### Visit all titles overviews and save links to all the titles to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3a3667d-6249-4a5a-a72c-18006624f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    overview = \"https://www.comicsdb.cz/prehled-comicsu/6/\"\n",
    "    list_of_links = []\n",
    "    for num in list(range(1,106)):\n",
    "        driver.get(f'{overview}{num}')    \n",
    "        time.sleep(2)\n",
    "        # wait for the element\n",
    "        table_ = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".table.table-hover.table-xs\")))\n",
    "        links = driver.find_elements(by = By.CSS_SELECTOR, value = \".table-border-dashed a\")\n",
    "        #links = links.find_elements(by = By.TAG_NAME, value = \"a\")\n",
    "        for link in links:\n",
    "            list_of_links.append([link.get_attribute(\"href\")])\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "filename = \"./data/links_titles.csv\"\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(list_of_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151a273-6f60-4abc-a133-4ad029491156",
   "metadata": {},
   "source": [
    "### Visit all the titles details and get all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9e2af4-5767-4e2c-ac8e-df8cad9ab14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    list_of_titles_data = []\n",
    "    with open(\"./data/links_titles.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            driver.get(row[0])\n",
    "            time.sleep(2)\n",
    "            title = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".font-weight-semibold\")))\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            title = soup.find(\"span\", \"font-weight-semibold\").text\n",
    "            basic_info = soup.find(\"small\")\n",
    "            try:\n",
    "                link_publisher = basic_info.find(\"a\").get(\"href\")\n",
    "            except:\n",
    "                link_publisher = \"NA\"\n",
    "            try:\n",
    "                year_pattern = re.compile(r'\\d{4}')\n",
    "                year = year_pattern.search(basic_info.text)\n",
    "                year = year.group()\n",
    "            except:            \n",
    "                year = \"NA\"\n",
    "            pages = \"NA\"\n",
    "            price = \"NA\"\n",
    "            dt_tags = soup.find_all(\"dt\")\n",
    "            for tag in dt_tags:\n",
    "                if \"Stran\" in tag.text:\n",
    "                    pages = tag.next_sibling.text\n",
    "                elif \"Cena\" in tag.text:\n",
    "                    price = tag.next_sibling.text\n",
    "            list_of_titles_data.append([title.strip(), year.strip(), row[0].strip(), link_publisher.strip(), pages.strip(), price.strip()])\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "filename = \"./data/output_titles_data.csv\"\n",
    "with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=\";\")\n",
    "    csvwriter.writerow([\"title\", \"year\", \"link_title\",\"link_publisher\", \"pages\", \"price\"])\n",
    "    csvwriter.writerows(list_of_titles_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e411459c-4c3e-4719-8664-5d1365d13d9c",
   "metadata": {},
   "source": [
    "### Clean the data from csv files, restructure them and import to sqlite3 db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c9daa2b-d57c-468f-8bf8-a53667bffa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10453 entries, 0 to 10452\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           10453 non-null  object \n",
      " 1   year            10453 non-null  int32  \n",
      " 2   link_title      10453 non-null  object \n",
      " 3   link_publisher  10391 non-null  object \n",
      " 4   pages           10453 non-null  int32  \n",
      " 5   price           9807 non-null   float64\n",
      " 6   publisher_id    10453 non-null  int32  \n",
      "dtypes: float64(1), int32(3), object(3)\n",
      "memory usage: 530.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "titles = pd.read_csv(\"./data/output_titles.csv\", delimiter=\";\")\n",
    "publishers = pd.read_csv(\"./data/output_publishers_data.csv\", delimiter=\";\")\n",
    "\n",
    "titles_origin = titles.copy()\n",
    "titles = titles[titles[\"link_publisher\"] == \"/nakladatelstvi/1/crew\"]\n",
    "titles[\"year\"] = titles[\"year\"].astype(int)\n",
    "mean_pages = titles[\"pages\"].mean()\n",
    "titles[\"pages\"] = titles[\"pages\"].fillna(mean_pages).astype(int)\n",
    "titles[\"price\"] = titles[\"price\"].str.replace(\" Kč\", \"\").astype(int)\n",
    "titles_origin[\"year\"] = titles_origin[\"year\"].fillna(0)\n",
    "titles_origin[\"year\"] = titles_origin[\"year\"].astype(int)\n",
    "mean_pages = titles_origin[\"pages\"].mean()\n",
    "titles_origin[\"pages\"] = titles_origin[\"pages\"].fillna(mean_pages).astype(int)\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].fillna(0)\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" Kč\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" h\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" K\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" k\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.replace(\" Lei\", \"\")\n",
    "titles_origin[\"price\"] = titles_origin[\"price\"].str.strip().astype(float)\n",
    "\n",
    "# Save some space - get the same part of url as in the titles csv file.\n",
    "publishers[\"link\"] = publishers[\"link\"].apply(lambda x: urlparse(x).path)\n",
    "publishers.rename(columns = {\"index\": \"publisher_id\"}, inplace = True)\n",
    "\n",
    "# import publishers to the db - let them get their pubsliher_id in the db and export, then joinig with titles from csv and fetch the pubslisher_id to the titles\n",
    "try:\n",
    "    conn = sqlite3.connect(\"./db/comics.db\")\n",
    "    cur = conn.cursor()\n",
    "    # import publishers df to the sqlite3 db, change the name of index to publisher_id\n",
    "    publishers.to_sql('publishers', conn, if_exists='replace', index=True, index_label='publisher_id')\n",
    "    result = cur.execute(\"SELECT * FROM publishers;\")\n",
    "    rows = result.fetchall()\n",
    "    columns = [column[0] for column in cur.description]\n",
    "    publishers_final = pd.DataFrame(rows, columns=columns)\n",
    "    titles_origin_final = titles_origin.merge(publishers_final, how=\"left\", left_on=\"link_publisher\", right_on=\"link\")\n",
    "    titles_origin_final.drop([\"name\", \"number_of_titles\", \"link\"],  axis = 1, inplace=True)\n",
    "    # renaming column\n",
    "    titles_origin_final.rename(columns = {\"index\": \"publisher_id\"}, inplace = True)\n",
    "    # if there is no publisher assign some special id\n",
    "    titles_origin_final[\"publisher_id\"] = titles_origin_final[\"publisher_id\"].fillna(999999)\n",
    "    titles_origin_final[\"publisher_id\"] = titles_origin_final[\"publisher_id\"].astype(int)\n",
    "    titles_origin_final.to_sql('titles', conn, if_exists='replace', index=True, index_label='title_id')\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782574d8-9c25-4390-abff-e2d50c0ca69e",
   "metadata": {},
   "source": [
    "### Explore the gathered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b19cd38-d40c-4656-8137-ea1473553b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10453 entries, 0 to 10452\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title_id        10453 non-null  int64  \n",
      " 1   title           10453 non-null  object \n",
      " 2   year            10453 non-null  int64  \n",
      " 3   link_title      10453 non-null  object \n",
      " 4   link_publisher  10391 non-null  object \n",
      " 5   pages           10453 non-null  int64  \n",
      " 6   price           9807 non-null   float64\n",
      " 7   publisher_id    10453 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 653.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 618 entries, 0 to 617\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   publisher_id      618 non-null    int64 \n",
      " 1   name              618 non-null    object\n",
      " 2   number_of_titles  618 non-null    int64 \n",
      " 3   link              618 non-null    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 19.4+ KB\n",
      "None None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npublishers = pd.read_csv(\"./data/output_publishers_data.csv\", delimiter=\";\")\\npublishers = publishers[publishers[\"number_of_titles\"] > 100]\\npublishers.plot(kind = \"bar\", x = \"name\", y = \"number_of_titles\")\\nplt.show() '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "def fetch_df_from_db(cursor, sql):\n",
    "    \"\"\"Gets cursor and SQL code and runs the SQL code on the cursor. Returns ready dataframe from the db data.\"\"\"\n",
    "    result = cursor.execute(sql)\n",
    "    rows = result.fetchall()\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    return pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(\"./db/comics.db\")\n",
    "    cur = conn.cursor()\n",
    "    titles_db = fetch_df_from_db(cur, \"SELECT * FROM titles;\")\n",
    "    publishers_db = fetch_df_from_db(cur, \"SELECT * FROM publishers;\")\n",
    "    print(titles_db.info(), publishers_db.info())\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "\"\"\"\n",
    "publishers = pd.read_csv(\"./data/output_publishers_data.csv\", delimiter=\";\")\n",
    "publishers = publishers[publishers[\"number_of_titles\"] > 100]\n",
    "publishers.plot(kind = \"bar\", x = \"name\", y = \"number_of_titles\")\n",
    "plt.show() \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
